{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/Users/eashan22/Desktop/DataMining/FinalProject/Dataset/train_data.csv',sep=',')\n",
    "train_label = pd.read_csv('/Users/eashan22/Desktop/DataMining/FinalProject/Dataset/train_label.csv',sep=',')\n",
    "test_data = pd.read_csv('/Users/eashan22/Desktop/DataMining/FinalProject/Dataset/test_data.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.replace(regex={'<.*?>|&nbsp|\\W':' '}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lvl2 = train_data[train_data.columns[3]] # train_X11\n",
    "train_lvl3 = train_data[train_data.columns[4]] # train_X12\n",
    "train_lvl23 = pd.concat([train_lvl2, train_lvl3], axis=1)  # train_X13\n",
    "\n",
    "train_XX = train_lvl23.fillna(axis=1,method='ffill')\n",
    "train_X1 = train_XX[train_XX.columns[1]]\n",
    "\n",
    "#train_X1=train_data[train_data.columns[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_price = train_data[train_data.columns[6]] #train_X22\n",
    "train_type = train_data[train_data.columns[7]] #train_X3\n",
    "train_y = train_label[train_label.columns[1:]]\n",
    "\n",
    "#train_X1=train_X1.dropna()\n",
    "# train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18141, 194)\n"
     ]
    }
   ],
   "source": [
    "train_X1 = pd.get_dummies(train_X1)\n",
    "train_P = (train_price - train_price.min()) / (train_price.max() - train_price.min())  #train_X2\n",
    "train_type = pd.get_dummies(train_type)\n",
    "\n",
    "train_X = pd.concat([train_X1, train_P,train_type], axis=1)\n",
    "train_y = np.ravel(train_y)\n",
    "\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import array\n",
    "# from numpy import argmax\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # integer encode\n",
    "# label_encoder = LabelEncoder()\n",
    "# price_encoded = label_encoder.fit_transform(train_X.price)\n",
    "\n",
    "# # onehot_encoder = OneHotEncoder()\n",
    "# # integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "# # onehot_encoded = onehot_encoder.fit_transform(train_X)\n",
    "# # onehot_encoded = pd.DataFrame(onehot_encoded)\n",
    "\n",
    "# price_encoded = pd.DataFrame(price_encoded)\n",
    "# train_X = train_X.append(price_encoded)\n",
    "# train_X.index = train_X.index-18142\n",
    "# train_X = train_X.fillna(0)\n",
    "# print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lvl2 = test_data[test_data.columns[3]]\n",
    "test_lvl3 = test_data[test_data.columns[4]]\n",
    "test_lvl23 = pd.concat([test_lvl2, test_lvl3], axis=1)\n",
    "\n",
    "test_XX = test_lvl23.fillna(axis=1,method='ffill')\n",
    "test_X1 = test_XX[test_XX.columns[1]]\n",
    "\n",
    "test_price = test_data[test_data.columns[6]]\n",
    "test_type = test_data[test_data.columns[7]]\n",
    "test_X1 = pd.get_dummies(test_X1)\n",
    "test_P = (test_price - test_price.min()) / (test_price.max() - test_price.min())\n",
    "test_type = pd.get_dummies(test_type)\n",
    "test_X4 = test_data[test_data.columns[0]]\n",
    "\n",
    "test_X = pd.concat([test_X1, test_P, test_type], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "price_encoded = label_encoder.fit_transform(test_X.price)\n",
    "# print(integer_encoded)\n",
    "\n",
    "price_encoded = pd.DataFrame(price_encoded)\n",
    "test_X = test_X.append(price_encoded)\n",
    "\n",
    "test_X = test_X.fillna(method='pad', axis=1)\n",
    "print(test_X.shape)\n",
    "# test_X = test_X.drop([x for x in range(6579,6603)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(train_X,train_y)\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "                    ('pca', PCA(n_components=3)),\n",
    "                    ('clf', LogisticRegression())])\n",
    "pipe_lr.fit(train_X, train_y)\n",
    "y_pred = model.predict_proba(test_X)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "param_grid = [{'clf__C': param_range, }]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_lr, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=13,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(train_X, train_y)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "\n",
    "clf = gs.best_estimator_\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "gs = GridSearchCV(estimator=pipe_lr,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=13)\n",
    "\n",
    "# Note: Optionally, you could use cv=2 \n",
    "# in the GridSearchCV above to produce\n",
    "# the 5 x 2 nested CV that is shown in the figure.\n",
    "\n",
    "scores = cross_val_score(gs, train_X, train_y, scoring='accuracy', cv=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.DataFrame(y_pred, columns=[0,'score'])\n",
    "Y_pred.index = Y_pred.index\n",
    "Y_pred = Y_pred.drop(0,axis=1)\n",
    "result = pd.concat([test_data['id'],Y_pred], axis=1)\n",
    "\n",
    "print(\"model.coef_: {}\".format(model.coef_))\n",
    "print(\"model.intercept_: {}\".format(model.intercept_))\n",
    "print(\"Training set score: {:.2f}\".format(model.score(train_X, train_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result\n",
    "# result.to_csv(\"/Users/eashan22/Desktop/DataMining/FinalProject/Dataset/results/LR_prl_20_.csv\",sep=',',index=0,float_format='%.8f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
